{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## **Evaluation Script for MEDIQA-CORR 2024**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: bert_score in c:\\users\\user\\appdata\\local\\programs\\pythoncodingpack\\lib\\site-packages (0.3.13)\n",
            "Requirement already satisfied: torch>=1.0.0 in c:\\users\\user\\appdata\\local\\programs\\pythoncodingpack\\lib\\site-packages (from bert_score) (2.2.0)\n",
            "Requirement already satisfied: pandas>=1.0.1 in c:\\users\\user\\appdata\\local\\programs\\pythoncodingpack\\lib\\site-packages (from bert_score) (1.1.0)\n",
            "Requirement already satisfied: transformers>=3.0.0 in c:\\users\\user\\appdata\\local\\programs\\pythoncodingpack\\lib\\site-packages (from bert_score) (4.37.2)\n",
            "Requirement already satisfied: numpy in c:\\users\\user\\appdata\\local\\programs\\pythoncodingpack\\lib\\site-packages (from bert_score) (1.24.3)\n",
            "Requirement already satisfied: requests in c:\\users\\user\\appdata\\local\\programs\\pythoncodingpack\\lib\\site-packages (from bert_score) (2.27.1)\n",
            "Requirement already satisfied: tqdm>=4.31.1 in c:\\users\\user\\appdata\\local\\programs\\pythoncodingpack\\lib\\site-packages (from bert_score) (4.66.1)\n",
            "Requirement already satisfied: matplotlib in c:\\users\\user\\appdata\\local\\programs\\pythoncodingpack\\lib\\site-packages (from bert_score) (3.3.1)\n",
            "Requirement already satisfied: packaging>=20.9 in c:\\users\\user\\appdata\\local\\programs\\pythoncodingpack\\lib\\site-packages (from bert_score) (23.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\user\\appdata\\local\\programs\\pythoncodingpack\\lib\\site-packages (from pandas>=1.0.1->bert_score) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in c:\\users\\user\\appdata\\local\\programs\\pythoncodingpack\\lib\\site-packages (from pandas>=1.0.1->bert_score) (2020.1)\n",
            "Requirement already satisfied: filelock in c:\\users\\user\\appdata\\local\\programs\\pythoncodingpack\\lib\\site-packages (from torch>=1.0.0->bert_score) (3.13.1)\n",
            "Collecting typing-extensions>=4.8.0 (from torch>=1.0.0->bert_score)\n",
            "  Using cached typing_extensions-4.10.0-py3-none-any.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: sympy in c:\\users\\user\\appdata\\local\\programs\\pythoncodingpack\\lib\\site-packages (from torch>=1.0.0->bert_score) (1.12)\n",
            "Requirement already satisfied: networkx in c:\\users\\user\\appdata\\local\\programs\\pythoncodingpack\\lib\\site-packages (from torch>=1.0.0->bert_score) (3.1)\n",
            "Requirement already satisfied: jinja2 in c:\\users\\user\\appdata\\local\\programs\\pythoncodingpack\\lib\\site-packages (from torch>=1.0.0->bert_score) (2.11.2)\n",
            "Requirement already satisfied: fsspec in c:\\users\\user\\appdata\\local\\programs\\pythoncodingpack\\lib\\site-packages (from torch>=1.0.0->bert_score) (2023.10.0)\n",
            "Requirement already satisfied: colorama in c:\\users\\user\\appdata\\local\\programs\\pythoncodingpack\\lib\\site-packages (from tqdm>=4.31.1->bert_score) (0.4.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in c:\\users\\user\\appdata\\local\\programs\\pythoncodingpack\\lib\\site-packages (from transformers>=3.0.0->bert_score) (0.20.3)\n",
            "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\user\\appdata\\local\\programs\\pythoncodingpack\\lib\\site-packages (from transformers>=3.0.0->bert_score) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\user\\appdata\\local\\programs\\pythoncodingpack\\lib\\site-packages (from transformers>=3.0.0->bert_score) (2023.12.25)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in c:\\users\\user\\appdata\\local\\programs\\pythoncodingpack\\lib\\site-packages (from transformers>=3.0.0->bert_score) (0.15.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\user\\appdata\\local\\programs\\pythoncodingpack\\lib\\site-packages (from transformers>=3.0.0->bert_score) (0.4.2)\n",
            "Requirement already satisfied: certifi>=2020.06.20 in c:\\users\\user\\appdata\\local\\programs\\pythoncodingpack\\lib\\site-packages (from matplotlib->bert_score) (2022.12.7)\n",
            "Requirement already satisfied: cycler>=0.10 in c:\\users\\user\\appdata\\local\\programs\\pythoncodingpack\\lib\\site-packages (from matplotlib->bert_score) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\user\\appdata\\local\\programs\\pythoncodingpack\\lib\\site-packages (from matplotlib->bert_score) (1.2.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\user\\appdata\\local\\programs\\pythoncodingpack\\lib\\site-packages (from matplotlib->bert_score) (10.0.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in c:\\users\\user\\appdata\\local\\programs\\pythoncodingpack\\lib\\site-packages (from matplotlib->bert_score) (2.4.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\user\\appdata\\local\\programs\\pythoncodingpack\\lib\\site-packages (from requests->bert_score) (1.26.14)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\user\\appdata\\local\\programs\\pythoncodingpack\\lib\\site-packages (from requests->bert_score) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\appdata\\local\\programs\\pythoncodingpack\\lib\\site-packages (from requests->bert_score) (2.10)\n",
            "Requirement already satisfied: six in c:\\users\\user\\appdata\\local\\programs\\pythoncodingpack\\lib\\site-packages (from cycler>=0.10->matplotlib->bert_score) (1.15.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\user\\appdata\\local\\programs\\pythoncodingpack\\lib\\site-packages (from jinja2->torch>=1.0.0->bert_score) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in c:\\users\\user\\appdata\\local\\programs\\pythoncodingpack\\lib\\site-packages (from sympy->torch>=1.0.0->bert_score) (1.3.0)\n",
            "Using cached typing_extensions-4.10.0-py3-none-any.whl (33 kB)\n",
            "Installing collected packages: typing-extensions\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.5.0\n",
            "    Uninstalling typing_extensions-4.5.0:\n",
            "      Successfully uninstalled typing_extensions-4.5.0\n",
            "Successfully installed typing-extensions-4.10.0\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow-intel 2.13.0 requires typing-extensions<4.6.0,>=3.6.6, but you have typing-extensions 4.10.0 which is incompatible.\n",
            "WARNING: There was an error checking the latest version of pip.\n"
          ]
        }
      ],
      "source": [
        "pip install bert_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow in c:\\users\\user\\appdata\\local\\programs\\pythoncodingpack\\lib\\site-packages (2.13.0)\n",
            "Requirement already satisfied: tensorflow-intel==2.13.0 in c:\\users\\user\\appdata\\local\\programs\\pythoncodingpack\\lib\\site-packages (from tensorflow) (2.13.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\user\\appdata\\local\\programs\\pythoncodingpack\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\user\\appdata\\local\\programs\\pythoncodingpack\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.1.21 in c:\\users\\user\\appdata\\local\\programs\\pythoncodingpack\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (23.5.26)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in c:\\users\\user\\appdata\\local\\programs\\pythoncodingpack\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\user\\appdata\\local\\programs\\pythoncodingpack\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\user\\appdata\\local\\programs\\pythoncodingpack\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\user\\appdata\\local\\programs\\pythoncodingpack\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (16.0.6)\n",
            "Requirement already satisfied: numpy<=1.24.3,>=1.22 in c:\\users\\user\\appdata\\local\\programs\\pythoncodingpack\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.24.3)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\user\\appdata\\local\\programs\\pythoncodingpack\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in c:\\users\\user\\appdata\\local\\programs\\pythoncodingpack\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (23.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\user\\appdata\\local\\programs\\pythoncodingpack\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (4.24.3)\n",
            "Requirement already satisfied: setuptools in c:\\users\\user\\appdata\\local\\programs\\pythoncodingpack\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (47.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in c:\\users\\user\\appdata\\local\\programs\\pythoncodingpack\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.15.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\user\\appdata\\local\\programs\\pythoncodingpack\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (2.3.0)\n",
            "Collecting typing-extensions<4.6.0,>=3.6.6 (from tensorflow-intel==2.13.0->tensorflow)\n",
            "  Using cached typing_extensions-4.5.0-py3-none-any.whl.metadata (8.5 kB)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\user\\appdata\\local\\programs\\pythoncodingpack\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.15.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\user\\appdata\\local\\programs\\pythoncodingpack\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.58.0)\n",
            "Requirement already satisfied: tensorboard<2.14,>=2.13 in c:\\users\\user\\appdata\\local\\programs\\pythoncodingpack\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (2.13.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.14,>=2.13.0 in c:\\users\\user\\appdata\\local\\programs\\pythoncodingpack\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (2.13.0)\n",
            "Requirement already satisfied: keras<2.14,>=2.13.1 in c:\\users\\user\\appdata\\local\\programs\\pythoncodingpack\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (2.13.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\user\\appdata\\local\\programs\\pythoncodingpack\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (0.31.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\user\\appdata\\local\\programs\\pythoncodingpack\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.13.0->tensorflow) (0.35.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\user\\appdata\\local\\programs\\pythoncodingpack\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.23.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in c:\\users\\user\\appdata\\local\\programs\\pythoncodingpack\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\user\\appdata\\local\\programs\\pythoncodingpack\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (3.4.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\user\\appdata\\local\\programs\\pythoncodingpack\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.27.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\user\\appdata\\local\\programs\\pythoncodingpack\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (0.7.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\user\\appdata\\local\\programs\\pythoncodingpack\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.3.7)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\user\\appdata\\local\\programs\\pythoncodingpack\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (5.3.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\user\\appdata\\local\\programs\\pythoncodingpack\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\user\\appdata\\local\\programs\\pythoncodingpack\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (4.9)\n",
            "Requirement already satisfied: urllib3<2.0 in c:\\users\\user\\appdata\\local\\programs\\pythoncodingpack\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (1.26.14)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\user\\appdata\\local\\programs\\pythoncodingpack\\lib\\site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in c:\\users\\user\\appdata\\local\\programs\\pythoncodingpack\\lib\\site-packages (from markdown>=2.6.8->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (6.8.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\appdata\\local\\programs\\pythoncodingpack\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\user\\appdata\\local\\programs\\pythoncodingpack\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\appdata\\local\\programs\\pythoncodingpack\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.10)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\user\\appdata\\local\\programs\\pythoncodingpack\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.1.3)\n",
            "Requirement already satisfied: zipp>=0.5 in c:\\users\\user\\appdata\\local\\programs\\pythoncodingpack\\lib\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (3.17.0)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in c:\\users\\user\\appdata\\local\\programs\\pythoncodingpack\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\user\\appdata\\local\\programs\\pythoncodingpack\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (3.2.2)\n",
            "Using cached typing_extensions-4.5.0-py3-none-any.whl (27 kB)\n",
            "Installing collected packages: typing-extensions\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.10.0\n",
            "    Uninstalling typing_extensions-4.10.0:\n",
            "      Successfully uninstalled typing_extensions-4.10.0\n",
            "Successfully installed typing-extensions-4.5.0\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "selenium 4.17.2 requires typing_extensions>=4.9.0, but you have typing-extensions 4.5.0 which is incompatible.\n",
            "torch 2.2.0 requires typing-extensions>=4.8.0, but you have typing-extensions 4.5.0 which is incompatible.\n",
            "WARNING: There was an error checking the latest version of pip.\n"
          ]
        }
      ],
      "source": [
        "pip install tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR: Could not find a version that satisfies the requirement bleurt (from versions: none)\n",
            "ERROR: No matching distribution found for bleurt\n",
            "WARNING: There was an error checking the latest version of pip.\n"
          ]
        }
      ],
      "source": [
        "pip install bleurt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: rouge in c:\\users\\user\\appdata\\local\\programs\\pythoncodingpack\\lib\\site-packages (1.0.1)\n",
            "Requirement already satisfied: six in c:\\users\\user\\appdata\\local\\programs\\pythoncodingpack\\lib\\site-packages (from rouge) (1.15.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: There was an error checking the latest version of pip.\n"
          ]
        }
      ],
      "source": [
        "pip install rouge"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "gather": {
          "logged": 1707888457570
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'bleurt'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-5-d7b6bdea289e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mrouge\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mRouge\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbert_score\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mbertscore\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mbleurt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mbleurtscore\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstats\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mstats\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'bleurt'"
          ]
        }
      ],
      "source": [
        "import re\n",
        "import pandas as pd\n",
        "from rouge import Rouge\n",
        "import bert_score.score as bertscore\n",
        "import bleurt.score as bleurtscore\n",
        "import scipy.stats as stats\n",
        "import numpy as np\n",
        "import math\n",
        "import string"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1707888457719
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "#################\n",
        "# Parsing Funcs #\n",
        "#################\n",
        "\n",
        "\n",
        "def parse_reference_file(filepath):\n",
        "    \"\"\"Parsing reference file path.\n",
        "\n",
        "    Returns:\n",
        "        reference_corrections (dict) {text_id: \"reference correction\"}\n",
        "        reference_flags (dict) {text_id: \"1 or 0 error flag\"}\n",
        "        reference_sent_id (dict) {text_id: \"error sentence id or -1\"}\n",
        "    \n",
        "    \"\"\"\n",
        "\n",
        "    reference_corrections = {}\n",
        "    reference_flags = {}\n",
        "    reference_sent_id = {}\n",
        "\n",
        "    df = pd.read_csv(filepath)\n",
        "    \n",
        "    for index, row in df.iterrows():\n",
        "        text_id = row['Text ID']\n",
        "        corrected_sentence = row['Corrected Sentence']\n",
        "        \n",
        "        if not isinstance(corrected_sentence, str):\n",
        "            if math.isnan(corrected_sentence):\n",
        "                corrected_sentence = \"NA\"\n",
        "            else:\n",
        "                corrected_sentence = str(corrected_sentence)\n",
        "                corrected_sentence = corrected_sentence.replace(\"\\n\", \" \") \\\n",
        "                  .replace(\"\\r\", \" \").strip()\n",
        "                  \n",
        "        reference_corrections[text_id] = corrected_sentence\n",
        "        reference_flags[text_id] = str(row['Error Flag'])\n",
        "        reference_sent_id[text_id] = str(row['Error Sentence ID'])\n",
        "\n",
        "    return reference_corrections, reference_flags, reference_sent_id\n",
        "\n",
        "\n",
        "def parse_run_submission_file(filepath):\n",
        "    \n",
        "    file = open(filepath, 'r')\n",
        "\n",
        "    candidate_corrections = {}\n",
        "    predicted_flags = {}\n",
        "    candidate_sent_id = {}\n",
        "    \n",
        "    lines = file.readlines()\n",
        "    \n",
        "    for line in lines:\n",
        "        line = line.strip()\n",
        "        \n",
        "        if len(line) == 0:\n",
        "            continue\n",
        "            \n",
        "        if not re.fullmatch('[a-z0-9\\-]+\\s[0-9]+\\s\\-?[0-9]+\\s.+', line):\n",
        "            print(\"Invalid line: \", line)\n",
        "            continue\n",
        "            \n",
        "        # replacing consecutive spaces\n",
        "        line = re.sub('\\s+', line, ' ')\n",
        "        \n",
        "        # parsing\n",
        "        items = line.split()\n",
        "        text_id = items[0]\n",
        "        error_flag = items[1]\n",
        "        sentence_id = items[2]\n",
        "        corrected_sentence = ' '.join(items[3:]).strip()\n",
        "        \n",
        "        # debug - parsing check\n",
        "        # print(\"{} -- {} -- {} -- {}\".format(text_id, error_flag, sentence_id, corrected_sentence))\n",
        "\n",
        "        predicted_flags[text_id] = error_flag\n",
        "        candidate_sent_id[text_id] = sentence_id\n",
        "\n",
        "        # processing candidate corrections\n",
        "        # removing quotes\n",
        "\n",
        "        while corrected_sentence.startswith('\"') and len(corrected_sentence) > 1:\n",
        "            corrected_sentence = corrected_sentence[1:]\n",
        "            \n",
        "        while corrected_sentence.endswith('\"') and len(corrected_sentence) > 1:\n",
        "            corrected_sentence = corrected_sentence[:-1]\n",
        "                   \n",
        "        if error_flag == '0':\n",
        "            # enforcing \"NA\" in predicted non-errors (used for consistent/reliable eval)\n",
        "            candidate_corrections[text_id] = \"NA\"\n",
        "        else:\n",
        "            candidate_corrections[text_id] = corrected_sentence\n",
        "\n",
        "    return candidate_corrections, predicted_flags, candidate_sent_id\n",
        "            "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1707888458074
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "##############\n",
        "# Eval Funcs #\n",
        "##############\n",
        "\n",
        "def compute_accuracy(reference_flags, reference_sent_id, predicted_flags, candidate_sent_id):\n",
        "    # Error Flags Accuracy (missing predictions are counted as false)\n",
        "    matching_flags_nb = 0\n",
        "    \n",
        "    for text_id in reference_flags:\n",
        "        if text_id in predicted_flags and reference_flags[text_id] == predicted_flags[text_id]:\n",
        "            matching_flags_nb += 1\n",
        "            \n",
        "    flags_accuracy = matching_flags_nb / len(reference_flags)\n",
        "    \n",
        "    # Error Sentence Detection Accuracy (missing predictions are counted as false)\n",
        "    matching_sentence_nb = 0\n",
        "    \n",
        "    for text_id in reference_sent_id:\n",
        "        if text_id in candidate_sent_id and candidate_sent_id[text_id] == reference_sent_id[text_id]:\n",
        "            matching_sentence_nb += 1\n",
        "            \n",
        "    sent_accuracy = matching_sentence_nb / len(reference_sent_id)\n",
        "\n",
        "    return {\n",
        "        \"Error Flags Accuracy\": flags_accuracy,\n",
        "        \"Error Sentence Detection Accuracy\": sent_accuracy\n",
        "    }\n",
        "\n",
        "def increment_counter(counters, counter_name):\n",
        "    counters[counter_name] = counters[counter_name] + 1\n",
        "\n",
        "def clip(value): # clip to a 0-1 value\n",
        "    return max(0, min(1, value))\n",
        "\n",
        "class NLGMetrics(object):\n",
        "\n",
        "    def __init__(self, metrics = ['ROUGE', 'BERTSCORE', 'BLEURT']): ## default metrics\n",
        "        self.metrics = metrics\n",
        "    \n",
        "    def compute(self, references, predictions, counters):\n",
        "        results = {}\n",
        "\n",
        "        assert len(predictions) == len(references), \"Predictions and references do not have the same size.\"\n",
        "        \n",
        "        results['aggregate_subset_check'] = np.array([0 for x in range(len(predictions))])\n",
        "        aggregate_components = 0\n",
        "\n",
        "        if 'ROUGE' in self.metrics:\n",
        "            rouge = Rouge() \n",
        "            rouge_scores = rouge.get_scores(predictions, references)\n",
        "                            \n",
        "            rouge1f_scores = []\n",
        "            rouge2f_scores = []\n",
        "            rougeLf_scores = []\n",
        "            \n",
        "            for i in range(len(references)):\n",
        "                r1f = rouge_scores[i][\"rouge-1\"][\"f\"]\n",
        "                r2f = rouge_scores[i][\"rouge-2\"][\"f\"]\n",
        "                rlf = rouge_scores[i][\"rouge-l\"][\"f\"]\n",
        "                \n",
        "                rouge1f_scores.append(r1f)\n",
        "                rouge2f_scores.append(r2f)\n",
        "                rougeLf_scores.append(rlf)\n",
        "                \n",
        "            # for checking comparison with composite\n",
        "            rouge1check = np.array(rouge1f_scores).mean()\n",
        "            rouge2check = np.array(rouge2f_scores).mean()\n",
        "            rougeLcheck = np.array(rougeLf_scores).mean()\n",
        "\n",
        "            results['R1F_subset_check'] = rouge1check\n",
        "            results['R2F_subset_check'] = rouge2check\n",
        "            results['RLF_subset_check'] = rougeLcheck\n",
        "\n",
        "            # rouge-1-f is used for the aggregate score\n",
        "            # sum element-wise for later aggregate score computation\n",
        "            results['aggregate_subset_check'] = results['aggregate_subset_check'] + np.array(rouge1f_scores)\n",
        "            aggregate_components += 1\n",
        "            \n",
        "            ###############################\n",
        "            # Composite score computation #\n",
        "            ###############################\n",
        "            \n",
        "            \"\"\"\n",
        "            NLG METRIC on sentence vs. sentence cases + ones or zeros \n",
        "            when either the reference or the candidate correction is NA\n",
        "            \"\"\"\n",
        "            \n",
        "            rouge1score = np.array(rouge1f_scores).sum()\n",
        "            rouge2score = np.array(rouge2f_scores).sum()\n",
        "            rougeLscore = np.array(rougeLf_scores).sum()\n",
        "            \n",
        "            composite_score_rouge1 = (rouge1score + counters[\"system_provided_correct_na\"]) / counters[\"total_texts\"]\n",
        "            composite_score_rouge2 = (rouge2score + counters[\"system_provided_correct_na\"]) / counters[\"total_texts\"]\n",
        "            composite_score_rougeL = (rougeLscore + counters[\"system_provided_correct_na\"]) / counters[\"total_texts\"]\n",
        "\n",
        "            results['R1FC'] = composite_score_rouge1\n",
        "            results['R2FC'] = composite_score_rouge2\n",
        "            results['RLFC'] = composite_score_rougeL\n",
        "\n",
        "        if 'BERTSCORE' in self.metrics:\n",
        "            bertScore_Precision, bertScore_Recall, bertScore_F1 = bertscore(predictions, references, model_type='microsoft/deberta-xlarge-mnli', lang='en', device ='cpu' , verbose=True, rescale_with_baseline=True) # roberta-large\n",
        "            \n",
        "            bertscores = bertScore_F1.numpy()\n",
        "            ## clip scores to [0,1]\n",
        "            bertscores = np.array([clip(num) for num in bertscores])\n",
        "\n",
        "            results['BERTSCORE_subset_check'] = bertscores.mean()\n",
        "            composite_score_bert = (bertscores.sum() + counters[\"system_provided_correct_na\"]) / counters[\"total_texts\"]\n",
        "            results['BERTC'] = composite_score_bert\n",
        "\n",
        "            # sum element-wise for later aggregate score computation\n",
        "            results['aggregate_subset_check'] = results['aggregate_subset_check'] + np.array(bertscores)\n",
        "            aggregate_components += 1\n",
        "\n",
        "            \n",
        "        if 'BLEURT' in self.metrics:\n",
        "            bleurtscorer = bleurtscore.BleurtScorer(checkpoint=\"BLEURT-20\")\n",
        "            \n",
        "            bleurtscores = bleurtscorer.score(references=references, candidates=predictions, batch_size =1)\n",
        "            ## clip scores to [0,1]\n",
        "            bleurtscores = np.array([clip(num) for num in bleurtscores])\n",
        "\n",
        "            results['BLEURT_subset_check'] = bleurtscores.mean()\n",
        "            composite_score_bleurt = (bleurtscores.sum() + counters[\"system_provided_correct_na\"]) / counters[\"total_texts\"]\n",
        "            results['BLEURTC'] = composite_score_bleurt\n",
        "\n",
        "            # sum element-wise for later aggregate score computation\n",
        "            results['aggregate_subset_check'] = results['aggregate_subset_check'] + np.array(bleurtscores) \n",
        "                    \n",
        "            aggregate_components += 1\n",
        "\n",
        "        if aggregate_components > 0:\n",
        "            aggregate_subset_scores = results['aggregate_subset_check'] / aggregate_components\n",
        "            composite_score_agg = (aggregate_subset_scores.sum() + counters[\"system_provided_correct_na\"]) / counters[\"total_texts\"]\n",
        "            \n",
        "            results['aggregate_subset_check'] = aggregate_subset_scores.mean() \n",
        "            results['AggregateC'] = composite_score_agg\n",
        "\n",
        "            \n",
        "\n",
        "        return results\n",
        "\n",
        "\n",
        "def get_nlg_eval_data(reference_corrections, candidate_corrections, remove_nonprint = False):\n",
        "    references = []\n",
        "    predictions = []\n",
        "    \n",
        "    counters = {\n",
        "        \"total_texts\": 0,\n",
        "        \"reference_na\": 0,\n",
        "        \"total_system_texts\": 0,\n",
        "        \"system_provided_na\": 0,\n",
        "        \"system_provided_correct_na\": 0,\n",
        "    }\n",
        "    \n",
        "    for text_id in reference_corrections:\n",
        "        increment_counter(counters, \"total_texts\")\n",
        "        \n",
        "        # removing non ascii chars\n",
        "        reference_correction = reference_corrections[text_id]\n",
        "        \n",
        "        if remove_nonprint:\n",
        "            reference_correction = ''.join(filter(lambda x: x in string.printable, str(reference_correction)))\n",
        "            \n",
        "        if reference_correction == \"NA\":\n",
        "            increment_counter(counters, \"reference_na\")\n",
        "            \n",
        "        if text_id in candidate_corrections:\n",
        "            increment_counter(counters, \"total_system_texts\")\n",
        "            candidate = candidate_corrections[text_id]\n",
        "            \n",
        "            if remove_nonprint:\n",
        "                candidate = ''.join(filter(lambda x: x in string.printable, candidate))\n",
        "                \n",
        "            if candidate == \"NA\":\n",
        "                increment_counter(counters, \"system_provided_na\")\n",
        "                \n",
        "            # matching NA counts as 1\n",
        "            if reference_correction == \"NA\" and candidate == \"NA\":\n",
        "                increment_counter(counters, \"system_provided_correct_na\")\n",
        "                continue\n",
        "                \n",
        "            # Run provided \"NA\" when a correction was required (=> 0)\n",
        "            # or Run provided a correction when \"NA\" was required (=> 0)\n",
        "            if candidate == \"NA\" or reference_correction == \"NA\":\n",
        "                continue\n",
        "                \n",
        "            # remaining case is both reference and candidate are not \"NA\"\n",
        "            # both are inserted/added for ROUGE/BLEURT/etc. computation\n",
        "            references.append(reference_correction)\n",
        "            predictions.append(candidate)\n",
        "    \n",
        "    return references, predictions, counters\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "reference_csv_file = 'C:/Users/USER/Documents/Maestria/CAOBA/Medical_Error/data/MEDIQA-CORR-2024-MS-ValidationSet-1.csv'\n",
        "\n",
        "# Aseg√∫rate de que el archivo se lea correctamente\n",
        "df = pd.read_csv(reference_csv_file)\n",
        "# Verificar que la columna 'Corrected Sentence' exista\n",
        "if 'Corrected Sentence' in df.columns:\n",
        "    print(\"La columna 'Corrected Sentence' existe.\")\n",
        "else:\n",
        "    print(\"La columna 'Corrected Sentence' no existe. Verifica el nombre y la estructura del archivo.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "submission_file = \"C:/Users/USER/Documents/Maestria/CAOBA/Medical_Error/data/prediction.txt\"\n",
        "\n",
        "try:\n",
        "    with open(submission_file, 'r', encoding='utf-8') as file:\n",
        "        content = file.read()\n",
        "except UnicodeDecodeError:\n",
        "    try:\n",
        "        with open(submission_file, 'r', encoding='ISO-8859-1') as file:\n",
        "            content = file.read()\n",
        "    except UnicodeDecodeError:\n",
        "        with open(submission_file, 'r', encoding='utf-8', errors='ignore') as file:\n",
        "            content = file.read()\n",
        "\n",
        "reference_csv_file = 'C:/Users/USER/Documents/Maestria/CAOBA/Medical_Error/data/MEDIQA-CORR-2024-MS-ValidationSet-1.csv'\n",
        "\n",
        "try:\n",
        "    df = pd.read_csv(reference_csv_file, encoding='utf-8')\n",
        "except UnicodeDecodeError:\n",
        "    try:\n",
        "        df = pd.read_csv(reference_csv_file, encoding='ISO-8859-1')\n",
        "    except UnicodeDecodeError:\n",
        "        df = pd.read_csv(reference_csv_file, encoding='utf-8', errors='ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1707888084660
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "\n",
        "reference_corrections, reference_flags, reference_sent_id = parse_reference_file(reference_csv_file)\n",
        "candidate_corrections, candidate_flags, candidate_sent_id = parse_run_submission_file(submission_file)\n",
        "\n",
        "# Accuracy\n",
        "accuracy_results = compute_accuracy(reference_flags, reference_sent_id, candidate_flags, candidate_sent_id)\n",
        "print(\"Accuracy Results:\\n\", accuracy_results)\n",
        "print()\n",
        "\n",
        "# NLG Eval for corrections\n",
        "references, predictions, counters = get_nlg_eval_data(reference_corrections, candidate_corrections)\n",
        "metrics = NLGMetrics(metrics = ['ROUGE', 'BERTSCORE', 'BLEURT']) # metrics = ['ROUGE', 'BERTSCORE', 'BLEURT']\n",
        "nlg_eval_results = metrics.compute(references, predictions, counters) \n",
        "\n",
        "\n",
        "print(\"NLG Eval Results:\\n\", nlg_eval_results) \n",
        "print()\n",
        "\n",
        "# debug check\n",
        "print(counters)\n",
        "print()\n"
      ]
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python38-azureml"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      },
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
